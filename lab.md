---
layout: page
title: Belle Lab
permalink: /lab/
---


The Lab carries out research in **artificial intelligence**, by unifying **learning** and **logic**, with a recent emphasis on *explainability* and *ethics*.

<img src="/uni.png" width="450"> 

We are motivated by the need to augment _learning_ and _perception_ with _high-level structured, commonsensical knowledge_, to enable systems to learn faster and more accurate models of the world. We are interested in developing computational frameworks that are able to _explain their decisions, modular, re-usable_, and _robust_ to variations in problem description. A non-exhaustive list of topics include:

*   probabilistic and statistical knowledge bases
*   ethics and explainability in AI 
*   exact and approximate probabilistic inference
*   statistical relational learning and causality
*   unifying deep learning and probabilistic learning methods
*   probabilistic programming
*   numerical optimization
*   automated planning and high-level programming
*   reinforcement learning and learning for automated planning
*   cognitive robotics
*   automated reasoning
*   modal logics (knowledge, action, belief)
*   multi-agent systems and epistemic planning
*   integrating causality and learning 

For example, our recent work has touched upon: 

*   [morality in machine learning systems](https://arxiv.org/pdf/1810.03736) 
*   [tractable learning with relational logic](/attachments/pacfol.pdf) 
*   [deep tractable probabilistic generative models](https://arxiv.org/pdf/1807.05464) 
*   [learning with missing data](https://arxiv.org/pdf/1901.05847)
*   [program learning for explainability](/attachments/ilp2019.pdf) 
*   [implementing fairness](https://arxiv.org/abs/1905.07026)
*   [model abstraction for explainability](https://arxiv.org/pdf/1810.02434) 
*   [strategies for interpretable & responsible AI](/attachments/biochem.pdf) 


**Faculty:** Vaishak Belle 

**Postdoctoral fellows and PhD students:**



*   _Miguel Mendez Lucero_, interested in neuro-symbolic AI
*   _Daxin Liu_ (Postdoctoral fellow with Royal Society), interested in probabilistic modal logics
*   _Xue Li_ (Postdoctoral fellow with Bjorn Ross), interested in counterfactuals and language models
*   _Antonio Miceli_ (Postdoctoral fellow with Cisco), interested in large language models, logic and vision
*   _Jessica Ciupa_ (Masters by Research), interested in RL and ethics 
*   _Nijesh Uperti_, interested in abstraction and logic-based learning
*   _Ruta Tang_, interested in large language models and logic 



**Alumni:**

*   _Benedicte Legastelois_ (Postdoctoral fellow with TAS project collaborators), interested in explainability
*   _Jonathan Feldstein_ (PhD 2024), interested in neuro-symbolic AI
*   _Andreas Bueff_ (PhD 2023), interested in tractable learning and reinforcement learning
*   _Giannis Papantonis_ (PhD 2023), interested in causality
*   _Ionela-Georgiana Mocanu_ (PhD 2023), interested in PAC learning
*   _Paulius Dilkas_ (PhD 2022), interested in model counting 
*   _Xin Du_ (Postdoctoral fellow with TAS project collaborators), interested in explainability 
*   _Am√©lie Levray_ (Postdoctoral fellow 2018-2019), interested in tractable learning with credal networks
*   _Eleanor Platt_ (research associate), interested in explainability 
*   _Amit Parag_ (MscR 2019), interested in tractable models and cosmological simulations  
*   _Rafael Karampatsis_ (Postdoctoral fellow 2019-2021), interested in ML interpretability 

**Associates:** 

*   _Sandor Bartha_ (with James Cheney, PhD 2023), interested in program induction
*   _Gary Smith_ (with Ron Petrick), interested in epistemic planning
*   _Xue Li_ (Postdoctoral fellow with ELIAI), interested in misinformation   
*   _Eddie Ungless_ (with Bjorn Ross), interested in NLP and bias
*   _Samuel Kolb_ (PhD 2019, KU Leuven, with Luc De Raedt), interested in inference for hybrid domains
*   _Davide Nitti_ (PhD 2016, KU Leuven, with Luc De Raedt), interested in machine learning for hybrid domains





**Visitors:**

*   _Esra Erdem_, Sabanci University
*   _Yoram Moses_, Technion
*   _Brendan Juba_, Washington University in St. Louis
*   _Loizos Michael_ (via the Alan Turing Institute), Open University of Cyprus
*   _Till Hoffman,_ RWTH Aachen University
*   _Xenia Heilmann_, Mainz University
*   _Chiara Manganini_, University of Milan 


**MSc Students:** 

If you are an Informatics MSc student at the University of Edinburgh, I supervise a number of theses on above topics. See, for example, the [publications](/papers) of other MSc students, including _Stefanie Speichert_ (ILP in hybrid domains), _Laszlo Treszkai_ (generalized planning), _Lewis Hammond_ (moral responsibility), and _Michael Varley_ (Fairness).
