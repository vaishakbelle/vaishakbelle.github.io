<!-- ---
layout: page  
title: XAI 
permalink: /pages/
--- -->



##  Logic meets Learning & Explainability in Machine Learning 

## Two tutorials to be held at [KR-2022](https://kr2022.cs.tu-dortmund.de) on August 1, 2022 

## Summary 

There will be two tutorials given on the same day at KR. The first will be on "Logic meets Learning", and the second will be on "Explainability in Machine Learning". 



## Details on Tutorial 1 

### Abstract 

 The tension between deduction and induction is perhaps the most fundamental issue in areas such as philosophy, cognition and artificial intelligence (AI). The deduction camp concerns itself with questions about the expressiveness of formal languages for capturing knowledge about the world, together with proof systems for reasoning from such knowledge bases. The learning camp attempts to generalize from examples about partial descriptions about the world. In AI, historically, these camps have loosely divided the development of the field, but advances in cross-over areas such as statistical relational learning, neuro-symbolic systems, and high-level control have illustrated that the dichotomy is not very constructive, and perhaps even ill-formed. In this tutorial, we survey work that provides further evidence for the connections between logic and learning. Our narrative is structured in terms of three strands: logic versus learning, machine learning for logic, and logic for machine learning, but naturally, there is considerable overlap. 


### Course Contents 

Motivation & background, logic vs learning (including weighted model counting), learning for logic (inductive logic programming, bayesian scoring, PAC-semantics), logic for learning (probabilistic programming, algebraic model counting, abstraction) 


### Who is this for

The course looks at fundamentals and assumes some knowledge of propositional and first-order logic. [Cf chapter to see contents covered.](https://vaishakbelle.com/attachments/03-Belle.pdf)

 
## Details on Tutorial 2 

### Abstract 


Explainability and interpretability has received considerable attention in almost all major AI conferences. However, the state of the art that is being published is somewhat inaccessible to most non-ML community members. How can the uninitiated AI researcher make sense and get herself acquainted with the literature?

In this tutorial, we provide an introduction to the fundamentals and taxonomy of ML explainability. We emphasize the interactive nature of explanations, discuss two popular techniques in detail and conclude with challenges to the area of explainability.
 
 
### Course Contents 

Motivation & background ([cf. paper](https://www.frontiersin.org/articles/10.3389/fdata.2021.688969/full)), explainability frameworks, 6 popular techniques around a stakeholder narrative (SHAP, Counterfactuals, Deletion Diagnostics, PDP/ICE, Anchors, Intrees), future directions and challenges to explainability.



### Who is this for

The course looks at more fundamental issues, and best benefits AI scientists, data scientists, undergraduate and graduate students who are not very familiar with state-of-the-art in ML explanability. Although we do mention and discuss state-of-the-art, material is focused on understanding key underlying issues and establishing basics. 


## Speaker 

[Vaishak Belle](https://vaishakbelle.com)




